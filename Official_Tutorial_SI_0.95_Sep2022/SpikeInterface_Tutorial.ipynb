{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeInterface DEMO v0.95 -  DCBT school Nijmegen - Sep 2022\n",
    "\n",
    "\n",
    "In this demo, you will use SpikeInterface to analyze a 64-channel dataset from am \"ASSY-156-P1\" probe from Cambridge Neurotech. \n",
    "The dataset is kindly provided by [Samuel McKenzie's Lab](https://mckenzieneurolab.com/). \n",
    "\n",
    "The objective of this demo is to show all the functionalities of SpikeInterface on a real-world example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "* [0. Preparation](#preparation)\n",
    "* [1. Loading the data and probe information](#loading)\n",
    "* [2. Preprocessing](#preprocessing)\n",
    "* [3. Saving and loading SpikeInterface objects](#save-load)\n",
    "* [4. Spike sorting](#spike-sorting)\n",
    "* [5. Extracting waveforms](#waveforms)\n",
    "* [6. Postprocessing](#postprocessing)\n",
    "* [7. Validation and curation](#curation)\n",
    "* [8. Spike sorting comparison](#comparison)\n",
    "* [9. Exporters](#exporters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparation <a class=\"anchor\" id=\"preparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the ephys data\n",
    "\n",
    "First, we need to download the recording. Feel free to use your own recordings as well later on. \n",
    "\n",
    "The dataset is called `cambridge_data.dat` and can be found on this [drive link](https://drive.google.com/drive/folders/1eWPuOd8q4MjpVpwazkWygQJDzJnToN3i) (`practice_2_real_dataset` folder). Move the dataset in the current folder.\n",
    "The recording was performed with the \"ASSY-156-P1\" probe with 4 shanks of 16 channels (in total 64 channels).\n",
    "\n",
    "\n",
    "### Import the modules\n",
    "\n",
    "Let's now import the `spikeinterface` modules that we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se \n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.widgets as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"SpikeInterface version: {si.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import spikeinterface_gui as sigui\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading recording and probe information <a class=\"anchor\" id=\"loading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "base_folder = Path('.')\n",
    "recording_file = base_folder / 'cambridge_data.bin'\n",
    "\n",
    "# parameters to load the bin/dat format\n",
    "num_channels = 64\n",
    "sampling_frequency = 20000\n",
    "gain_to_uV = 0.195\n",
    "offset_to_uV = 0\n",
    "dtype = \"int16\"\n",
    "time_axis = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = si.read_binary(recording_file, num_chan=num_channels, sampling_frequency=sampling_frequency,\n",
    "                           dtype=dtype, gain_to_uV=gain_to_uV, offset_to_uV=offset_to_uV, \n",
    "                           time_axis=time_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_binary()` function returns a `RecordingExtractor` object. We can print it to visualize some of its properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can further `annotate` the recording to tell SI that it is not filtered yet. This will prevent further mistakes in the pipieline, such as attempting to extract waveforms from unfiltered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.annotate(is_filtered=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "While the `read_binary()` function is part of the `core` module (as it's used internally by SI to store data in a convenient format), the `extractor` module allows you to load many file formats used in electrophysiology. \n",
    "\n",
    "The extractors available in SI are all loaded using the [NEO](https://neo.readthedocs.io/en/stable/) python package.\n",
    "\n",
    "We can access the full list of available extractors with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se.recording_extractor_full_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `RecordingExtractor` object extracts information about channel ids, channel locations (if present), the sampling frequency of the recording, and the extracellular traces (when prompted). The `BinaryRecordingExtractor` is designed specifically for raw binary files datasets (.bin, .dat, .raw).\n",
    "\n",
    "Here we load information from the recording using the built-in functions from the RecordingExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = recording.get_channel_ids()\n",
    "fs = recording.get_sampling_frequency()\n",
    "num_chan = recording.get_num_channels()\n",
    "num_segments = recording.get_num_segments()\n",
    "\n",
    "print(f'Channel ids: {channel_ids}')\n",
    "print(f'Sampling frequency: {fs}')\n",
    "print(f'Number of channels: {num_chan}')\n",
    "print(f\"Number of segments: {num_segments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpikeInterface supports multi-segment recordings. A segment is a contiguous piece of data, and sometimes recordings can be made of multiple acquisitions, for examples a baseline, a stimulation phase, and a post recording. In such cases, the recording object will be made of multiple segments and be treated as such over the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `get_traces()` function returns a TxN numpy array where N is the number of channel ids passed in (all channel ids are passed in by default) and T is the number of frames (determined by start_frame and end_frame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trace_snippet = recording.get_traces(start_frame=int(fs*0), end_frame=int(fs*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Traces shape:', trace_snippet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `widgets` module includes several convenient plotting functions that can be used to explore the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before moving on with the analysis, we have to load the probe information. For this we will use the [ProbeInterface](https://probeinterface.readthedocs.io/en/main/index.html) package. \n",
    "\n",
    "ProbeInterface allows to easily create, manipulate, and visualize neural probes. Moreover, it comes with a wide range of IO functions to import and export existing formats. Finally, we have created a public library of commercial probes (https://gin.g-node.org/spikeinterface/probeinterface_library/) that can be retrieved with a single line of code.\n",
    "\n",
    "Let's import `probeinterface`, download the probe and plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import probeinterface as pi\n",
    "from probeinterface.plotting import plot_probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "manufacturer = 'cambridgeneurotech'\n",
    "probe_name = 'ASSY-156-P-1'\n",
    "\n",
    "probe = pi.get_probe(manufacturer, probe_name)\n",
    "print(probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In most experiments, the neural probe has a connector, that is interfaced to an headstage, which in turn connects to the acquisition system. This *pathway* usually results in a channel remapping, which means that the order of the contacts on the probe is different than the order of the recorded traces.\n",
    "\n",
    "`probeinterface` provides a growing collection of common pathways that can be loaded directly to wire a device and apply the correct channel mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pi.get_available_pathways()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe.wiring_to_device('ASSY-156>RHD2164')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "plot_probe(probe, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "plot_probe(probe, with_contact_id=True, with_device_index=True, ax=ax)\n",
    "ax.set_xlim(-50, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probe now has contact ids `id#` and device ids `dev#`! We can also visualize the probe information as a `pandas` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe.to_dataframe(complete=True).loc[:, [\"contact_ids\", \"shank_ids\", \"device_channel_indices\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that also the `shank_id` is loaded with the probe.\n",
    "\n",
    "A `probeinterface` object can be loaded directly to a SI recording object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_prb = recording.set_probe(probe, group_mode=\"by_shank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading the probe, the device indices (and all the other contact properties) are automatically sorted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_rec = recording_prb.get_probe()\n",
    "probe_rec.to_dataframe(complete=True).loc[:, [\"contact_ids\", \"shank_ids\", \"device_channel_indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Channels after loading the probe file: {recording_prb.get_channel_ids()}')\n",
    "print(f'Channel groups after loading the probe file: {recording_prb.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts = sw.plot_timeseries(recording_prb, order_channel_by_depth=True, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Properties \n",
    "\n",
    "`RecordingExtractor` object can have *properties*. A property is a piece of information attached to a channel, e.g. group or location.\n",
    "\n",
    "Similarly, for `SortingExtractor` objects (that we'll cover later), anything related to a unit can be stored as a property. \n",
    "\n",
    "We can check which properties are in the extractor as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Properties before loading the probe:\", list(recording.get_property_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Properties after loading the probe:\", list(recording_prb.get_property_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After loading the probe we now have some new properties: `contact_vector`, `location`, and `group`.\n",
    "\n",
    "Let's add some new properties! \n",
    "The first 32 channels are in the CA1 area, the second 32 are in the CA3 area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "brain_area_property_values = ['CA1']*32 + ['CA3']*32\n",
    "print(brain_area_property_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_prb.set_property(key='brain_area', values=brain_area_property_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also specify a property on a subset of channels. In this case, the non-specified channels will be filled empty values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recording_prb.set_property(key='quality', values=[\"good\"]*(recording_prb.get_num_channels() - 3),\n",
    "                           ids=recording_prb.get_channel_ids()[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_prb.get_property(\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Properties after adding custom properties:\", list(recording_prb.get_property_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Internally the properties is jus a dictionary attached to the recording that is accessible as `_properties`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recording_prb._properties.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Annotations* can be attached to any object and they can carry any information related to the recording or sorting objects.\n",
    "\n",
    "Let's add an annotation about this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recording_prb.annotate(description=\"Dataset for SI 0.93 tutorial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recording_prb.get_annotation_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing <a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "\n",
    "\n",
    "Now that the probe information is loaded we can do some preprocessing using `toolkit` module.\n",
    "\n",
    "We can filter the recordings, rereference the signals to remove noise, discard noisy channels, whiten the data, remove stimulation artifacts, etc. (more info [here](https://spiketoolkit.readthedocs.io/en/latest/preprocessing_example.html)).\n",
    "\n",
    "For this notebook, let's filter the recordings and apply common median reference (CMR). All preprocessing modules return new `RecordingExtractor` objects that apply the underlying preprocessing function. This allows users to access the preprocessed data in the same way as the raw data.\n",
    "\n",
    "We will focus only on the first shank (grouo `0`) for the following analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recordings_by_group = recording_prb.split_by(\"group\")\n",
    "print(recordings_by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_to_process = recordings_by_group[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_to_process.get_num_channels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Below, we bandpass filter the recording and apply common median reference to the original recording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recording_f = st.bandpass_filter(recording_to_process, freq_min=300, freq_max=6000)\n",
    "\n",
    "w = sw.plot_timeseries(recording_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that the after filtering we can observe spiking activity on many channels! We can also apply other preprocessing steps to further increase the quality of the recording. \n",
    "\n",
    "For examplem let's apply Common Median Reference (CMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cmr = st.common_reference(recording_f, reference='global', operator='median')\n",
    "recording_cmr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the traces after applying CMR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_timeseries(recording_cmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take only 5 min. for demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since we are going to spike sort the data, let's first cut out a 5-minute recording, to speed up computations.\n",
    "\n",
    "We can easily do so with the `frame_slice()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fs = recording_cmr.get_sampling_frequency()\n",
    "recording_sub = recording_cmr.frame_slice(start_frame=0*fs, end_frame=300*fs)\n",
    "recording_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Saving and loading SpikeInterface objects <a class=\"anchor\" id=\"save-load\"></a>\n",
    "\n",
    "All operations in SpikeInterface are *lazy*, meaning that they are not performed if not needed. This is why the creation of our filter recording was almost instantaneous. However, to speed up further processing, we might want to **save** it to a file and perform those operations (eg. filters, CMR, etc.) at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recording_saved = recording_sub.save(folder=base_folder/\"preprocessed\", progress_bar=True, \n",
    "                                     n_jobs=4, total_memory=\"100M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we inspect the `preprocessed` folder, we find that a few files have been saved. Let's take a look at what they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls -ll {base_folder}/preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `traces_cached_seg0.raw` contains the processed raw data, while the `.json` files include information on how to reload the binary file. The `provenance.json` includes the information of the recording before saving it to a binary file, and the `probe.json` represents the probe object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `save` returns a new *cached* recording that has all the previously loaded information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Cached channels ids: {recording_saved.get_channel_ids()}')\n",
    "print(f'Channel groups after caching: {recording_saved.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After saving the SI object, we can easily load it back in a new session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recording_loaded = si.load_extractor(base_folder/\"preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loaded channels ids: {recording_loaded.get_channel_ids()}')\n",
    "print(f'Channel groups after loading: {recording_loaded.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check that the traces are exactly the same as the `recording_saved` that we saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2)\n",
    "w_saved = sw.plot_timeseries(recording_saved, ax=axs[0])\n",
    "w_loaded = sw.plot_timeseries(recording_loaded, ax=axs[1])\n",
    "axs[0].set_title(\"Saved\")\n",
    "axs[1].set_title(\"Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**IMPORTANT**: the same saving mechanisms are available also for all SortingExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Spike sorting <a class=\"anchor\" id=\"spike-sorting\"></a>\n",
    "\n",
    "We can now run spike sorting on the above recording. We will use `tridesclous` and `ironclust` for this demonstration, to show how easy SpikeInterface makes it easy to interchengably run different sorters :)\n",
    "\n",
    "Let's first check the installed sorters in spiketoolkit to see if herdingspikes is available. Then we can then check the `tridesclous` default parameters.\n",
    "We will sort the bandpass cached filtered recording the `recording_saved` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.installed_sorters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the parameters associated to any sorter with the `get_default_params()` function from the `sorters` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss.get_default_params('tridesclous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.get_params_description('tridesclous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss.run_sorter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.run_tridesclous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To modify a parameter, we can easily pass it to the `run` function as an extra argument!\n",
    "For example, let's set the `filter` parameter to False as the recording is already preprocessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run spike sorting on entire recording\n",
    "sorting_TDC = ss.run_sorter('tridesclous', recording_sub, \n",
    "                            output_folder=base_folder/'results_TDC', verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_TDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found', len(sorting_TDC.get_unit_ids()), 'units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SpikeInterface ensures full provenance of the spike sorting pipeline. Upon running a spike sorter, a `spikeinterface_params.json` file is saved in the `output_folder`. This contains a `.json` version of the recording and all the input parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls {base_folder}/results_TDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {base_folder}/results_TDC/spikeinterface_params.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing IronClust (requires MATLAB)\n",
    "\n",
    "For MATLAB-based sorters, all you need to do is cloning the sorter repo and point it to SpikeInterface:\n",
    "\n",
    "Let's clone ironclust in the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/flatironinstitute/ironclust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now all we have to tell the IronClustSorter class where is the ironclust repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss.IronClustSorter.set_ironclust_path('./ironclust')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that we can also set a global environment variable called `IRONCLUST_PATH`. In that case we don't need to set the path in each session because the sorter class looks for this environment variable.\n",
    "\n",
    "Now ironclust should be installed and we can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss.IronClustSorter.ironclust_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.installed_sorters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run spike sorting by group\n",
    "sorting_IC = ss.run_sorter('ironclust', recording_saved, \n",
    "                              output_folder=base_folder/'results_IC',\n",
    "                              verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'IronClust found {len(sorting_IC.get_unit_ids())} units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The spike sorting returns a `SortingExtractor` object. Let's see some of its functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ironclust unit ids: {sorting_IC.get_unit_ids()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Spike train of a unit: {sorting_IC.get_unit_spike_train(13)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use `spikewidgets` functions for some quick visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w_rs = sw.plot_rasters(sorting_IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Running multiple sorter jobs in parallel\n",
    "\n",
    "So far we have seen how to run one sorter at a time. SI provides a convenient launcher in order to run multiple sorters on multiple recordings with one line of code!\n",
    "\n",
    "The `run_sorters()` function of the `sorter` module allows you to specify a list of sorters to use on a list (or dictionary) of parameters. The jobs are by default ran in a loop, but the `engine` argument enables to specify a parallel backend (`joblib` or `dask`) and relative parameters.\n",
    "\n",
    "In the following example, we run the 2 jobs to run `herdingspikes` and `ironclust` in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorting_outputs = ss.run_sorters(sorter_list=[\"tridesclous\", \"ironclust\"],\n",
    "                                 recording_dict_or_list={\"group0\": recording_saved},\n",
    "                                 working_folder=base_folder / \"all_sorters\",\n",
    "                                 verbose=True,\n",
    "                                 engine=\"joblib\",\n",
    "                                 engine_kwargs={'n_jobs': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned `sorting_outputs` variable is a dictionary that has (rec_name, sorter_name) as keys, and the `SortingExtractor` objects as valus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorting_outputs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the tutorial, let's pick the `ironclust` output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_IC = sorting_outputs[('group0', 'ironclust')]\n",
    "sorting_IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike sort in Docker containers\n",
    "###  (Linux and MacOS only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some sorters are hard to install! To alleviate this headache, SI provides a built-in mechanism to run a spike sorting job in a docker container.\n",
    "\n",
    "We are maintaining a set of sorter-specific docker files in the [spikeinterface-dockerfiles repo](<https://github.com/SpikeInterface/spikeinterface-dockerfiles>)\n",
    "and most of the docker images are available on Docker Hub from the [SpikeInterface organization](<https://hub.docker.com/orgs/spikeinterface/repositories>).\n",
    "\n",
    "Running spike sorting in a docker container just requires to:\n",
    "\n",
    "1. have docker installed\n",
    "2. have docker python SDK installed (`pip install docker`)\n",
    "\n",
    "When docker is installed, you can simply run the sorter in a specified docker image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sorting_SC = ss.run_spykingcircus(recording_saved, output_folder=\"/data_local/DataSpikeSorting/results_SC\",\n",
    "                                  docker_image=\"spikeinterface/spyking-circus-base:1.0.7\", \n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sw.plot_rasters(sorting_SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Extracting waveforms <a class=\"anchor\" id=\"waveforms\"></a>\n",
    "\n",
    "The core of postprocessing spike sorting results revolves around extracting waveforms from paired recording-sorting objects.\n",
    "\n",
    "**NEW** In the SI API, waveforms are extracted using the `WaveformExtractor` class in the `core` module.\n",
    "\n",
    "The `WaveformExtractor` object has convenient functions to retrieve waveforms and templates.\n",
    "Let's see how it works.\n",
    "\n",
    "To extract the waveforms, we can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "si.extract_waveforms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we = si.extract_waveforms(recording_saved, sorting_IC, folder=base_folder / \"wf_IC\", progress_bar=True,\n",
    "                          n_jobs=4, total_memory=\"500M\", overwrite=False, load_if_exists=True)\n",
    "print(we)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now all waveforms are computed and stored in the provided `wf_IC` folder. We can now retrieve waveforms and templates easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms0 = we.get_waveforms(unit_id=0)\n",
    "print(f\"Waveforms shape: {waveforms0.shape}\")\n",
    "template0 = we.get_template(unit_id=0)\n",
    "print(f\"Template shape: {template0.shape}\")\n",
    "all_templates = we.get_all_templates()\n",
    "print(f\"All templates shape: {all_templates.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For waveforms, the dimension is (num_spikes, num_samples, num_channels), while each template has dimension (num_samples, num_channels). Note that the number of spikes in this case is 500..we'll get back to it later!\n",
    "\n",
    "The `WaveformExtractor` is also compatible with several `widgets` to visualize the spike sorting output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_unit_waveforms(we, unit_ids=[2, 3, 4])\n",
    "w = sw.plot_unit_templates(we, unit_ids=[2, 3, 4])\n",
    "w = sw.plot_unit_probe_map(we, unit_ids=[2,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_unit_summary(we, unit_id=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noticed before, the number of spikes for the waveforms is 500. Let's check the number of spikes for other waveforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit in sorting_IC.get_unit_ids():\n",
    "    waveforms = we.get_waveforms(unit_id=unit)\n",
    "    spiketrain = sorting_IC.get_unit_spike_train(unit)\n",
    "    print(f\"Unit {unit} - num waveforms: {waveforms.shape[0]} - num spikes: {len(spiketrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No units have more than 500 spikes! This is because by default, the `WaveformExtractor` extracts waveforms on a random subset of 500 spikes. To extract waveforms on all spikes, we can use the `max_spikes_per_unit` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_all = si.extract_waveforms(recording_saved, sorting_IC, folder=base_folder / \"wf_IC_all\", \n",
    "                              max_spikes_per_unit=None, progress_bar=True, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit in sorting_IC.get_unit_ids():\n",
    "    waveforms = we_all.get_waveforms(unit_id=unit)\n",
    "    spiketrain = sorting_IC.get_unit_spike_train(unit)\n",
    "    print(f\"Unit {unit} - num waveforms: {waveforms.shape[0]} - num spikes: {len(spiketrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now waveforms have been extracted for all spikes! Let's move on to explore the postprocessing capabilities of the `toolkit` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Postprocessing <a class=\"anchor\" id=\"postprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessing spike sorting results ranges from computing additional information, such as spike amplitudes and Principal Component Analisys (PCA) scores, to computing features of the extracellular waveforms, similarity between templates and crosscorrelograms. All of this is possible with the `toolkit` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### PCA scores\n",
    "\n",
    "PCA scores can be easily computed with the `compute_principal_components()` function. Similarly to the `extract_waveforms`, the function returns an object of type `WaveformPrincipalComponent` that allows to retrieve all pc scores on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.compute_principal_components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = st.compute_principal_components(we, n_components=3, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pc0 = pc.get_components(unit_id=0)\n",
    "print(f\"PC scores shape: {pc0.shape}\")\n",
    "all_labels, all_pcs = pc.get_all_components()\n",
    "print(f\"All PC scores shape: {all_pcs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pc scores of a single unit, the dimension is (num_spikes, num_components, num_channels). \n",
    "The `get_all_components()` function returns an array with the label/unit id for each component (`all_labels`) and an array of dimension (num_all_samples, num_components, num_channels). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spike amplitudes can be computed with the `get_spike_amplitudes` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = st.compute_spike_amplitudes(we, outputs=\"concatenated\", progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_amplitudes_distribution(we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_amplitudes_timeseries(we, unit_ids=[3, 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By default, all amplitudes are concatenated in one array.\n",
    "\n",
    "The correspinding spike times and labels can be easily retrieved as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_spike_times, all_spike_labels = sorting_IC.get_all_spike_trains()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [0] index is to select the first segment. In case of multiple segments each element will correspond to a different segment and will contain spike times and labels for that segment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute template metrics\n",
    "\n",
    "Template metrics, or extracellular features, such as peak to valley duration or full-width half maximum, are important to classify neurons into putative classes (excitatory - inhibitory). The `toolkit` allows one to compute several of these metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.get_template_metric_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "template_metrics = st.calculate_template_metrics(we)\n",
    "display(template_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For more information about these template metrics, we refer to this [documentation](https://github.com/AllenInstitute/ecephys_spike_sorting/tree/master/ecephys_spike_sorting/modules/mean_waveforms) from the Allen Institute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Viewers <a class=\"anchor\" id=\"viewers\"></a>\n",
    "\n",
    "Let's check put the `spikeinterface-gui` to explore our spike sorting results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!sigui wf_IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 8. Validation and curation <a class=\"anchor\" id=\"curation\"></a>\n",
    "\n",
    "The `toolkit` module also provides several functions to compute qualitity metrics to validate the spike sorting results.\n",
    "\n",
    "Let's see what metrics are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.get_quality_metric_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qc = st.compute_quality_metrics(we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For more information about these waveform features, we refer to this [documentation](https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_quality_metrics.html) from the Allen Institute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Automatic curation based on quality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A viable option to curate (or at least pre-curate) a spike sorting output is to filter units based on quality metrics. As we have already computed quality metrics a few lines above, we can simply filter the `qc` dataframe based on some thresholds.\n",
    "\n",
    "Here, we'll only keep units with an SNR > 5 and an ISI violation threshold < 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "snr_thresh = 5\n",
    "isi_viol_thresh = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A straightforward way to filter a pandas dataframe is via the `query`.\n",
    "We first define our query (make sure the names match the column names of the dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "our_query = f\"snr > {snr_thresh} & isi_violations_rate < {isi_viol_thresh}\"\n",
    "print(our_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "and then we can use the query to select units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keep_units = qc.query(our_query)\n",
    "keep_unit_ids = keep_units.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_auto = sorting_IC.select_units(keep_unit_ids)\n",
    "print(f\"Number of units before curation: {len(sorting_IC.get_unit_ids())}\")\n",
    "print(f\"Number of units after curation: {len(sorting_auto.get_unit_ids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Spike sorting comparison <a class=\"anchor\" id=\"comparison\"></a>\n",
    "\n",
    "Can we combine the output of multiple sorters to curate the spike sorting output?\n",
    "\n",
    "To answer this question we can use the `comparison` module.\n",
    "We first compare and match the output spike trains of the different sorters, and we can then extract a new `SortingExtractor` with only the units in agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare 2 by two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = comp_TDC_IC = sc.compare_two_sorters(sorting_TDC, sorting_IC, 'TDC', 'IC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_agreement_matrix(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = comp_TDC_IC = sc.compare_two_sorters(sorting_SC, sorting_IC, 'SC', 'IC')\n",
    "sw.plot_agreement_matrix(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = comp_TDC_IC = sc.compare_two_sorters(sorting_SC, sorting_TDC, 'SC', 'TDC')\n",
    "sw.plot_agreement_matrix(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmp = sc.compare_multiple_sorters([sorting_TDC, sorting_IC, sorting_SC], ['TDC', 'IC', 'SC'], \n",
    "                                   spiketrain_mode='union', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_multicomp_agreement(mcmp)\n",
    "w = sw.plot_multicomp_agreement_by_sorter(mcmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sw.plot_multicomp_graph(mcmp, draw_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_sorting = mcmp.get_agreement_sorting(minimum_agreement_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_rasters(agreement_sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 9. Exporters <a class=\"anchor\" id=\"exporters\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Export to Phy for manual curation\n",
    "\n",
    "To perform manual curation we can export the data to [Phy](https://github.com/cortex-lab/phy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.exporters import export_to_phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "export_to_phy(we_all, output_folder=base_folder / 'phy_IC',\n",
    "              progress_bar=True, total_memory='100M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!phy template-gui phy_IC/params.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After curating the results we can reload it using the `PhySortingExtractor` and exclude the units that we labeled as `noise`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_IC_phy_curated = se.PhySortingExtractor(base_folder / 'phy_IC/', exclude_cluster_groups=['noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of units before curation: {len(sorting_IC.get_unit_ids())}\")\n",
    "# in manual curation, 4 units were labeled as noise:\n",
    "print(f\"Number of units after curation: {len(sorting_IC_phy_curated.get_unit_ids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export spike sorting report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.exporters import export_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "export_report(waveform_extractor=we, output_folder=base_folder/\"SI_report\", format=\"png\", show_figures=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls {base_folder}/SI_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {base_folder}/SI_report/units/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Et voilà"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
